\documentclass[10pt, conference]{IEEEtran}

\input{setup}
\usepackage{balance}
\usepackage{balance}
\usepackage{amssymb,amsmath}
\usepackage{wrapfig}
\usepackage{multirow}
\usepackage{graphicx}
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{times}
\usepackage{cite}
\usepackage{fancybox}
\usepackage{color}
\usepackage{array}
\usepackage{subfigure}
\usepackage{balance}
\usepackage{epstopdf}
\usepackage{array}
%\usepackage{subfig}
%\usepackage{xspace}
\def\UrlBreaks{\do\/\do-} %to break the urls, all in one line



\newcommand{\conclusionbox}[1]{%
	\vspace{2mm}
	\framebox[0.45\textwidth][c]{%
		\parbox[b]{0.42\textwidth}{%
			{\it #1}
		}
	}
	\vspace{2mm}
}

\newcommand{\emad}[1]{\textcolor{red}{{\it [Emad says: #1]}}}
%\newcommand{\todo}[1]{\colorbox{yellow}{\textbf{[#1]}}}


\newcommand{\rqi}{\textbf{}}
\newcommand{\rqii}{\textbf{}}
\newcommand{\rqiii}{\textbf{}}

\begin{document}
\title{Studying the Discrepancy between Performance Testing Results from Virtual and Physical Environments}

\author{\IEEEauthorblockN{Muhammad Moiz Arif, Weiyi Shang, Emad Shihab}

\IEEEauthorblockA{Department of Computer Science and Software Engineering\\Concordia University,
Montreal, Canada\\
\url{{mo_ari,shang,eshihab}@encs.concordia.ca}}}

\maketitle

\begin{abstract}
Performance plays an indispensable role for software reliability. 
%The unreliability of software systems in the field is often caused by performance issues than functional bugs. 
Performance tests are typically conducted in order to ensure the performance of software systems. Such performance tests often consume large amounts of computing resources, such as long running time in the performance testing environments. Making it worse, the ever evolving field environment requires frequently updating the performance testing environment. In practice, virtual machines (VMs) are widely exploited to provide flexible and less costly environments for performance tests. However, the use of VMs may introduce extra overheads (e.g., a higher than expected memory utilization) to the testing environment, leading to un-realistic performance testing results. Yet, to the best of our knowledge, little research has studied such overhead in the context of performance testing activities, nor has investigated the impact on performance testing results. 
		
In this paper, we perform a case study on two open source systems, i.e., Dell DVD Store and CloudStore, to evaluate the discrepancy between the performance testing results from virtual and physical environments. We conduct the same performance tests in both virtual and physical environments. In order to evaluate the discrepancy, we compare the performance testing results based on the three aspects that are typically examined for performance testing results: 1) individual performance metric, 2) relationship among performance metrics and 3) performance models that are build from the performance metrics. Our results illustrate the discrepancy between performance testing results from virtual and physical environments. In particular, individual performance metrics from virtual and physical environments do not share the same shape of distribution. The correlations among performance metrics in virtual environment are different from the correlations in physical environment. Finally, the statistical models that are built based on the performance counters from virtual environment are different from the models that are build from the physical environment. Normalizing performance metrics based on deviance may reduced such discrepancy. Practitioners should be aware of such discrepancy and may leverage normalization techniques when analyzing performance testing results from virtual environments.


		
		
	%	activities, including performance modeling and performance regression detection. The two activities are conducted in both environments that consists of physical machines or VMs. We observed that the comparison between the virtual and physical environments is not straight forward. We also observed that the performance of our subject systems between two environments is not identical.
		
	%	\textcolor{red}{(insert implications)}
	
%	\textit{Keywords--Performance engineering; Performance testing; Performance modeling; Performance analysis}	
	\end{abstract}
	

\section{Introduction}
\label{sec:introduction}
\input{introduction}

\section{Related Work}
\label{sec:related_work}
\input{related_work}

\section{Case Study Setup}
\label{sec:case_study_setup}
\input{case_study_setup}

\section{Case Study Results}
\label{sec:results}
\input{results}

\section{Discussion}
\label{sec:discussion}
\input{discussion}

\section{Threats to validity}
\label{sec:threats_to_validity}
\input{threats_to_validity}

\section{Conclusion}
\label{sec:conclusion}
\input{conclusion}

\bibliographystyle{IEEEtran}
\bibliography{bibliography}

\end{document}
